# Copy to .env and fill values for the providers you want to enable.
# Leaving required keys empty will mark the provider as not-configured;
# health endpoints and provider/contract tests will skip with a clear reason.
# Endpoints default to hosted APIsâ€”override for private gateways or local dev.

# OpenAI (required: OPENAI_API_KEY)
OPENAI_API_KEY=
OPENAI_ENDPOINT=https://api.openai.com/v1          # optional; override for proxy/Azure
OPENAI_ORG=                                        # optional; org scoping
OPENAI_API_VERSION=                                # optional; required for Azure/preview versions

# Gemini / Vertex (provide GEMINI_API_KEY or Vertex settings; empty disables)
GEMINI_API_KEY=
GEMINI_ENDPOINT=https://generativelanguage.googleapis.com/v1beta
VERTEX_PROJECT=                                    # optional; set when using Vertex
VERTEX_LOCATION=                                   # optional; e.g. us-central1

# GLM4 (required: GLM4_API_KEY)
GLM4_API_KEY=
GLM4_ENDPOINT=https://open.bigmodel.cn/api/paas/v4

# OpenRouter (required: OPENROUTER_API_KEY)
OPENROUTER_API_KEY=
OPENROUTER_ENDPOINT=https://openrouter.ai/api/v1

# SiliconFlow (required: SILICONFLOW_API_KEY)
SILICONFLOW_API_KEY=
SILICONFLOW_ENDPOINT=https://api.siliconflow.cn/v1

# Cerebras (required: CEREBRAS_API_KEY)
CEREBRAS_API_KEY=
CEREBRAS_ENDPOINT=https://api.cerebras.ai/v1

# ModelScope (required: MODELSCOPE_API_KEY)
MODELSCOPE_API_KEY=
MODELSCOPE_ENDPOINT=https://api.modelscope.cn/v1

# Groq (required: GROQ_API_KEY)
GROQ_API_KEY=
GROQ_ENDPOINT=https://api.groq.com/openai/v1

# Ollama / vLLM local (optional; leave empty to disable)
OLLAMA_ENDPOINT=http://localhost:11434/v1
