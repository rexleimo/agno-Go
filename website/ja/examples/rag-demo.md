# RAG (Retrieval-Augmented Generation) ãƒ‡ãƒ¢

## æ¦‚è¦

ã“ã®ä¾‹ã§ã¯ã€Agno-Go ã‚’ä½¿ç”¨ã—ã¦ RAG ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚RAG ã¯ã€çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®æƒ…å ±æ¤œç´¢ã¨ LLM ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’çµ„ã¿åˆã‚ã›ã¦ã€æ­£ç¢ºã§æ ¹æ‹ ã®ã‚ã‚‹å›ç­”ã‚’æä¾›ã—ã¾ã™ã€‚ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã« ChromaDBã€OpenAI åŸ‹ã‚è¾¼ã¿ã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢æ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ  RAG ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

## å­¦ã¹ã‚‹ã“ã¨

- OpenAI åŸ‹ã‚è¾¼ã¿ã®ä½œæˆã¨ä½¿ç”¨æ–¹æ³•
- ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ ChromaDB ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹æ–¹æ³•
- æœ€é©ãªæ¤œç´¢ã®ãŸã‚ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯åŒ–ã™ã‚‹æ–¹æ³•
- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç”¨ã®ã‚«ã‚¹ã‚¿ãƒ  RAG ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•
- çŸ¥è­˜æ¤œç´¢æ©Ÿèƒ½ã‚’æŒã¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹æ–¹æ³•
- RAG å®Ÿè£…ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

## å‰ææ¡ä»¶

- Go 1.21 ä»¥é™
- OpenAI API ã‚­ãƒ¼
- ChromaDB ãŒãƒ­ãƒ¼ã‚«ãƒ«ã§å®Ÿè¡Œä¸­ (Docker çµŒç”±)

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

1. OpenAI API ã‚­ãƒ¼ã‚’è¨­å®šã—ã¾ã™:
```bash
export OPENAI_API_KEY=sk-your-api-key-here
```

2. Docker ã‚’ä½¿ç”¨ã—ã¦ ChromaDB ã‚’èµ·å‹•ã—ã¾ã™:
```bash
docker pull chromadb/chroma
docker run -p 8000:8000 chromadb/chroma
```

3. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•ã—ã¾ã™:
```bash
cd cmd/examples/rag_demo
```

## å®Œå…¨ãªã‚³ãƒ¼ãƒ‰

```go
package main

import (
	"context"
	"fmt"
	"log"
	"os"

	"github.com/rexleimo/agno-go/pkg/agno/agent"
	openaiembed "github.com/rexleimo/agno-go/pkg/agno/embeddings/openai"
	"github.com/rexleimo/agno-go/pkg/agno/knowledge"
	openaimodel "github.com/rexleimo/agno-go/pkg/agno/models/openai"
	"github.com/rexleimo/agno-go/pkg/agno/tools/toolkit"
	"github.com/rexleimo/agno-go/pkg/agno/vectordb"
	"github.com/rexleimo/agno-go/pkg/agno/vectordb/chromadb"
)

// RAGToolkit provides knowledge retrieval tools for the agent
type RAGToolkit struct {
	*toolkit.BaseToolkit
	vectorDB vectordb.VectorDB
}

// NewRAGToolkit creates a new RAG toolkit
func NewRAGToolkit(db vectordb.VectorDB) *RAGToolkit {
	t := &RAGToolkit{
		BaseToolkit: toolkit.NewBaseToolkit("knowledge_retrieval"),
		vectorDB:    db,
	}

	// Register search function
	t.RegisterFunction(&toolkit.Function{
		Name:        "search_knowledge",
		Description: "Search the knowledge base for relevant information. Use this to find answers to user questions.",
		Parameters: map[string]toolkit.Parameter{
			"query": {
				Type:        "string",
				Description: "The search query or question",
				Required:    true,
			},
			"limit": {
				Type:        "integer",
				Description: "Maximum number of results to return (default: 3)",
				Required:    false,
			},
		},
		Handler: t.searchKnowledge,
	})

	return t
}

func (t *RAGToolkit) searchKnowledge(ctx context.Context, args map[string]interface{}) (interface{}, error) {
	query, ok := args["query"].(string)
	if !ok {
		return nil, fmt.Errorf("query must be a string")
	}

	limit := 3
	if l, ok := args["limit"].(float64); ok {
		limit = int(l)
	}

	results, err := t.vectorDB.Query(ctx, query, limit, nil)
	if err != nil {
		return nil, fmt.Errorf("failed to search knowledge base: %w", err)
	}

	// Format results for the agent
	var formattedResults []map[string]interface{}
	for i, result := range results {
		formattedResults = append(formattedResults, map[string]interface{}{
			"rank":     i + 1,
			"content":  result.Content,
			"score":    result.Score,
			"metadata": result.Metadata,
		})
	}

	return formattedResults, nil
}

func main() {
	fmt.Println("ğŸš€ RAG (Retrieval-Augmented Generation) Demo")
	fmt.Println("This example demonstrates:")
	fmt.Println("1. Loading documents from files")
	fmt.Println("2. Chunking text into smaller pieces")
	fmt.Println("3. Generating embeddings with OpenAI")
	fmt.Println("4. Storing in ChromaDB vector database")
	fmt.Println("5. Using RAG with an Agent to answer questions")
	fmt.Println()

	// Check environment variables
	openaiKey := os.Getenv("OPENAI_API_KEY")
	if openaiKey == "" {
		log.Fatal("OPENAI_API_KEY environment variable is required")
	}

	ctx := context.Background()

	// Step 1: Create embedding function
	fmt.Println("ğŸ“Š Step 1: Creating OpenAI embedding function...")
	embedFunc, err := openaiembed.New(openaiembed.Config{
		APIKey: openaiKey,
		Model:  "text-embedding-3-small",
	})
	if err != nil {
		log.Fatalf("Failed to create embedding function: %v", err)
	}
	fmt.Printf("   âœ… Created embedding function (model: %s, dimensions: %d)\n\n",
		embedFunc.GetModel(), embedFunc.GetDimensions())

	// Step 2: Create ChromaDB vector database
	fmt.Println("ğŸ’¾ Step 2: Connecting to ChromaDB...")
	db, err := chromadb.New(chromadb.Config{
		BaseURL:           "http://localhost:8000",
		CollectionName:    "rag_demo",
		EmbeddingFunction: embedFunc,
	})
	if err != nil {
		log.Fatalf("Failed to create ChromaDB: %v", err)
	}
	defer db.Close()

	// Create collection
	err = db.CreateCollection(ctx, "", map[string]interface{}{
		"description": "RAG demo knowledge base",
	})
	if err != nil {
		log.Fatalf("Failed to create collection: %v", err)
	}
	fmt.Println("   âœ… Connected to ChromaDB and created collection")

	// Step 3: Load and process documents
	fmt.Println("ğŸ“š Step 3: Loading and processing documents...")

	// Sample documents about AI and ML
	sampleDocs := []knowledge.Document{
		{
			ID:      "doc1",
			Content: "Artificial Intelligence (AI) is the simulation of human intelligence by machines. AI systems can perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. Modern AI is based on machine learning algorithms that can learn from data.",
			Metadata: map[string]interface{}{
				"topic": "AI Overview",
				"date":  "2025-01-01",
			},
		},
		{
			ID:      "doc2",
			Content: "Machine Learning (ML) is a subset of AI that focuses on creating systems that learn from data. Instead of being explicitly programmed, ML models improve their performance through experience. Common ML algorithms include neural networks, decision trees, and support vector machines.",
			Metadata: map[string]interface{}{
				"topic": "Machine Learning",
				"date":  "2025-01-01",
			},
		},
		{
			ID:      "doc3",
			Content: "Vector databases are specialized databases designed to store and query high-dimensional vector embeddings. They enable semantic search by finding similar vectors using distance metrics like cosine similarity or Euclidean distance. Vector databases are essential for RAG (Retrieval-Augmented Generation) systems.",
			Metadata: map[string]interface{}{
				"topic": "Vector Databases",
				"date":  "2025-01-01",
			},
		},
		{
			ID:      "doc4",
			Content: "Retrieval-Augmented Generation (RAG) combines information retrieval with text generation. It first retrieves relevant documents from a knowledge base, then uses a language model to generate responses based on the retrieved context. RAG improves accuracy and reduces hallucinations in AI systems.",
			Metadata: map[string]interface{}{
				"topic": "RAG",
				"date":  "2025-01-01",
			},
		},
		{
			ID:      "doc5",
			Content: "Large Language Models (LLMs) like GPT-4 are neural networks trained on vast amounts of text data. They can understand and generate human-like text, perform reasoning, answer questions, and even write code. LLMs are the foundation of modern AI assistants and chatbots.",
			Metadata: map[string]interface{}{
				"topic": "Large Language Models",
				"date":  "2025-01-01",
			},
		},
	}

	// Chunk documents (optional, useful for large documents)
	chunker := knowledge.NewCharacterChunker(500, 50)
	var allChunks []knowledge.Chunk
	for _, doc := range sampleDocs {
		chunks, err := chunker.Chunk(doc)
		if err != nil {
			log.Printf("Warning: Failed to chunk document %s: %v", doc.ID, err)
			continue
		}
		allChunks = append(allChunks, chunks...)
	}
	fmt.Printf("   âœ… Loaded %d documents, created %d chunks\n", len(sampleDocs), len(allChunks))

	// Step 4: Generate embeddings and store in vector DB
	fmt.Println("\nğŸ”¢ Step 4: Generating embeddings and storing in ChromaDB...")

	var vdbDocs []vectordb.Document
	for _, chunk := range allChunks {
		vdbDocs = append(vdbDocs, vectordb.Document{
			ID:       chunk.ID,
			Content:  chunk.Content,
			Metadata: chunk.Metadata,
			// Embedding will be generated automatically by ChromaDB
		})
	}

	err = db.Add(ctx, vdbDocs)
	if err != nil {
		log.Fatalf("Failed to add documents to vector DB: %v", err)
	}

	count, _ := db.Count(ctx)
	fmt.Printf("   âœ… Stored %d documents in vector database\n\n", count)

	// Step 5: Test retrieval
	fmt.Println("ğŸ” Step 5: Testing knowledge retrieval...")
	testQuery := "What is machine learning?"
	results, err := db.Query(ctx, testQuery, 2, nil)
	if err != nil {
		log.Fatalf("Failed to query: %v", err)
	}

	fmt.Printf("   Query: \"%s\"\n", testQuery)
	fmt.Printf("   Found %d relevant documents:\n", len(results))
	for i, result := range results {
		fmt.Printf("   %d. [Score: %.4f] %s\n", i+1, result.Score,
			truncate(result.Content, 80))
	}
	fmt.Println()

	// Step 6: Create RAG-powered Agent
	fmt.Println("ğŸ¤– Step 6: Creating RAG-powered Agent...")

	// Create OpenAI model
	model, err := openaimodel.New("gpt-4o-mini", openaimodel.Config{
		APIKey:      openaiKey,
		Temperature: 0.7,
		MaxTokens:   500,
	})
	if err != nil {
		log.Fatalf("Failed to create model: %v", err)
	}

	// Create RAG toolkit
	ragToolkit := NewRAGToolkit(db)

	// Create agent with RAG capabilities
	ag, err := agent.New(agent.Config{
		Name:     "RAG Assistant",
		Model:    model,
		Toolkits: []toolkit.Toolkit{ragToolkit},
		Instructions: `You are a helpful AI assistant with access to a knowledge base.
When users ask questions:
1. Use the search_knowledge tool to find relevant information
2. Base your answer on the retrieved information
3. Cite the sources when possible
4. If you can't find relevant information, say so

Always be helpful, accurate, and concise.`,
		MaxLoops: 5,
	})
	if err != nil {
		log.Fatalf("Failed to create agent: %v", err)
	}
	fmt.Println("   âœ… Agent created with RAG capabilities")

	// Step 7: Interactive Q&A
	fmt.Println("ğŸ’¬ Step 7: Interactive Q&A (RAG in action)")
	fmt.Println("=" + string(make([]byte, 60)) + "=")

	questions := []string{
		"What is artificial intelligence?",
		"Explain the difference between AI and machine learning",
		"What are vector databases used for?",
		"How does RAG improve AI systems?",
	}

	for i, question := range questions {
		fmt.Printf("\n[Question %d] User: %s\n", i+1, question)

		output, err := ag.Run(ctx, question)
		if err != nil {
			log.Printf("Error: %v", err)
			continue
		}

		fmt.Printf("Assistant: %s\n", output.Content)
	}

	fmt.Println("\n" + string(make([]byte, 60)) + "=")
	fmt.Println("\nâœ… RAG Demo completed successfully!")
	fmt.Println("\nKey Takeaways:")
	fmt.Println("â€¢ Documents are chunked and embedded automatically")
	fmt.Println("â€¢ Vector database enables semantic search")
	fmt.Println("â€¢ Agent uses RAG to provide accurate, grounded answers")
	fmt.Println("â€¢ Citations and sources improve trustworthiness")

	// Cleanup
	fmt.Println("\nğŸ§¹ Cleaning up...")
	err = db.DeleteCollection(ctx, "rag_demo")
	if err != nil {
		log.Printf("Warning: Failed to delete collection: %v", err)
	} else {
		fmt.Println("   âœ… Deleted demo collection")
	}
}

func truncate(s string, maxLen int) string {
	if len(s) <= maxLen {
		return s
	}
	return s[:maxLen] + "..."
}
```

## ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜

### 1. ã‚«ã‚¹ã‚¿ãƒ  RAG ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ

```go
type RAGToolkit struct {
	*toolkit.BaseToolkit
	vectorDB vectordb.VectorDB
}
```

RAG ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã¯ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒ©ãƒƒãƒ—ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå‘¼ã³å‡ºã›ã‚‹ `search_knowledge` é–¢æ•°ã‚’å…¬é–‹ã—ã¾ã™:

- ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—ã¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®åˆ¶é™ã‚’å—ã‘å…¥ã‚Œã‚‹
- ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯é¡ä¼¼æ€§ã‚’ä½¿ç”¨ã—ã¦ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ¤œç´¢
- é–¢é€£æ€§ã‚¹ã‚³ã‚¢ã‚’å«ã‚€æ•´å½¢ã•ã‚ŒãŸçµæœã‚’è¿”ã™

### 2. OpenAI åŸ‹ã‚è¾¼ã¿

```go
embedFunc, err := openaiembed.New(openaiembed.Config{
	APIKey: openaiKey,
	Model:  "text-embedding-3-small",
})
```

- OpenAI ã® `text-embedding-3-small` ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ (1536 æ¬¡å…ƒ)
- ãƒ†ã‚­ã‚¹ãƒˆã‚’å¯†ãªãƒ™ã‚¯ãƒˆãƒ«è¡¨ç¾ã«å¤‰æ›
- ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯é¡ä¼¼æ€§æ¤œç´¢ã‚’å¯èƒ½ã«ã™ã‚‹

### 3. ChromaDB ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹

```go
db, err := chromadb.New(chromadb.Config{
	BaseURL:           "http://localhost:8000",
	CollectionName:    "rag_demo",
	EmbeddingFunction: embedFunc,
})
```

- ãƒ­ãƒ¼ã‚«ãƒ« ChromaDB ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«æ¥ç¶š
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŸ‹ã‚è¾¼ã¿ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¿½åŠ ã•ã‚Œã‚‹ã¨è‡ªå‹•çš„ã«åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆ

### 4. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°

```go
chunker := knowledge.NewCharacterChunker(500, 50)
```

- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ 500 æ–‡å­—ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
- ãƒãƒ£ãƒ³ã‚¯é–“ã® 50 æ–‡å­—ã®é‡è¤‡
- ãƒãƒ£ãƒ³ã‚¯å¢ƒç•Œã‚’è¶Šãˆã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿æŒ
- é•·ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ¤œç´¢ç²¾åº¦ã‚’å‘ä¸Š

### 5. RAG æ©Ÿèƒ½ã‚’æŒã¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

```go
ag, err := agent.New(agent.Config{
	Name:     "RAG Assistant",
	Model:    model,
	Toolkits: []toolkit.Toolkit{ragToolkit},
	Instructions: `You are a helpful AI assistant with access to a knowledge base.
When users ask questions:
1. Use the search_knowledge tool to find relevant information
2. Base your answer on the retrieved information
3. Cite the sources when possible
4. If you can't find relevant information, say so`,
	MaxLoops: 5,
})
```

æŒ‡ç¤ºã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ä¼ãˆã¾ã™:
- çŸ¥è­˜æ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’ã„ã¤ä½¿ç”¨ã™ã‚‹ã‹
- æ¤œç´¢ã•ã‚ŒãŸæƒ…å ±ã‚’ã©ã®ã‚ˆã†ã«çµ„ã¿è¾¼ã‚€ã‹
- é€æ˜æ€§ã®ãŸã‚ã«ã‚½ãƒ¼ã‚¹ã‚’å¼•ç”¨ã™ã‚‹ã“ã¨
- æƒ…å ±ãŒåˆ©ç”¨ã§ããªã„å ´åˆã«æ­£ç›´ã§ã‚ã‚‹ã“ã¨

## ã‚µãƒ³ãƒ—ãƒ«ã®å®Ÿè¡Œ

```bash
# ChromaDB ãŒå®Ÿè¡Œä¸­ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
docker run -p 8000:8000 chromadb/chroma

# ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ
go run main.go
```

## æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›

```
ğŸš€ RAG (Retrieval-Augmented Generation) Demo
This example demonstrates:
1. Loading documents from files
2. Chunking text into smaller pieces
3. Generating embeddings with OpenAI
4. Storing in ChromaDB vector database
5. Using RAG with an Agent to answer questions

ğŸ“Š Step 1: Creating OpenAI embedding function...
   âœ… Created embedding function (model: text-embedding-3-small, dimensions: 1536)

ğŸ’¾ Step 2: Connecting to ChromaDB...
   âœ… Connected to ChromaDB and created collection

ğŸ“š Step 3: Loading and processing documents...
   âœ… Loaded 5 documents, created 5 chunks

ğŸ”¢ Step 4: Generating embeddings and storing in ChromaDB...
   âœ… Stored 5 documents in vector database

ğŸ” Step 5: Testing knowledge retrieval...
   Query: "What is machine learning?"
   Found 2 relevant documents:
   1. [Score: 0.8234] Machine Learning (ML) is a subset of AI that focuses on creating syste...
   2. [Score: 0.7156] Artificial Intelligence (AI) is the simulation of human intelligence b...

ğŸ¤– Step 6: Creating RAG-powered Agent...
   âœ… Agent created with RAG capabilities

ğŸ’¬ Step 7: Interactive Q&A (RAG in action)
============================================================

[Question 1] User: What is artificial intelligence?
Assistant: Based on the knowledge base, Artificial Intelligence (AI) is the simulation of human intelligence by machines. AI systems can perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. Modern AI is based on machine learning algorithms that can learn from data.

[Question 2] User: Explain the difference between AI and machine learning
Assistant: AI (Artificial Intelligence) is the broader concept of machines simulating human intelligence to perform various tasks. Machine Learning (ML) is a subset of AI that specifically focuses on creating systems that learn from data rather than being explicitly programmed. So while all ML is AI, not all AI is ML. ML improves performance through experience, using algorithms like neural networks and decision trees.

[Question 3] User: What are vector databases used for?
Assistant: According to the knowledge base, vector databases are specialized databases designed to store and query high-dimensional vector embeddings. They enable semantic search by finding similar vectors using distance metrics like cosine similarity or Euclidean distance. Vector databases are essential for RAG (Retrieval-Augmented Generation) systems.

[Question 4] User: How does RAG improve AI systems?
Assistant: RAG (Retrieval-Augmented Generation) improves AI systems by combining information retrieval with text generation. The process first retrieves relevant documents from a knowledge base, then uses a language model to generate responses based on the retrieved context. This approach improves accuracy and reduces hallucinations in AI systems by grounding responses in actual knowledge.

============================================================

âœ… RAG Demo completed successfully!

Key Takeaways:
â€¢ Documents are chunked and embedded automatically
â€¢ Vector database enables semantic search
â€¢ Agent uses RAG to provide accurate, grounded answers
â€¢ Citations and sources improve trustworthiness

ğŸ§¹ Cleaning up...
   âœ… Deleted demo collection
```

## ä¸»è¦ãªæ¦‚å¿µ

### RAG ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

1. **å–ã‚Šè¾¼ã¿**: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒèª­ã¿è¾¼ã¾ã‚Œã€ãƒãƒ£ãƒ³ã‚¯åŒ–ã•ã‚Œã‚‹
2. **åŸ‹ã‚è¾¼ã¿**: ãƒãƒ£ãƒ³ã‚¯ãŒãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ã«å¤‰æ›ã•ã‚Œã‚‹
3. **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: åŸ‹ã‚è¾¼ã¿ãŒãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã•ã‚Œã‚‹
4. **æ¤œç´¢**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªãŒåŸ‹ã‚è¾¼ã¾ã‚Œã€é¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚‹
5. **ç”Ÿæˆ**: LLM ãŒæ¤œç´¢ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦å›ç­”ã‚’ç”Ÿæˆ

### ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢

ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã¨ã¯ç•°ãªã‚Šã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã¯æ„å‘³ã«åŸºã¥ã„ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¦‹ã¤ã‘ã¾ã™:

- ã‚¯ã‚¨ãƒª: "What is ML?"
- ãƒãƒƒãƒ: "Machine Learning"ã€"neural networks"ã€"training models" ã«é–¢ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- å®Œå…¨ä¸€è‡´ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹

### ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥

ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯æ¤œç´¢å“è³ªã«å½±éŸ¿ã—ã¾ã™:

- **ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º (500)**: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ç²¾åº¦ã®ãƒãƒ©ãƒ³ã‚¹
  - å°ã•ã™ãã‚‹: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å¤±ã†
  - å¤§ãã™ãã‚‹: ç„¡é–¢ä¿‚ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ¤œç´¢

- **é‡è¤‡ (50)**: é‡è¦ãªæƒ…å ±ã®åˆ†å‰²ã‚’é˜²ã
  - ãƒãƒ£ãƒ³ã‚¯é–“ã®é€£ç¶šæ€§ã‚’ç¢ºä¿
  - å¢ƒç•Œã‚’ã¾ãŸãæ–‡ã«ã¨ã£ã¦é‡è¦

### ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ

RAG ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã¯ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«ã®æ§‹ç¯‰æ–¹æ³•ã‚’ç¤ºã—ã¾ã™:

```go
t.RegisterFunction(&toolkit.Function{
	Name:        "search_knowledge",
	Description: "Search the knowledge base...",
	Parameters: map[string]toolkit.Parameter{
		"query": {
			Type:        "string",
			Description: "The search query",
			Required:    true,
		},
	},
	Handler: t.searchKnowledge,
})
```

ä¸»è¦ãªè¦ç´ :
- LLM ãŒç†è§£ã™ã‚‹ãŸã‚ã®æ˜ç¢ºãªåå‰ã¨èª¬æ˜
- å‹ã‚’æŒã¤æ˜ç¢ºã«å®šç¾©ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
- ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…ã™ã‚‹ãƒãƒ³ãƒ‰ãƒ©ãƒ¼é–¢æ•°

## é«˜åº¦ãªæ©Ÿèƒ½

### ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã§çµæœã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã§ãã¾ã™:

```go
results, err := db.Query(ctx, query, limit, map[string]interface{}{
	"topic": "Machine Learning",
	"date": map[string]interface{}{
		"$gte": "2025-01-01",
	},
})
```

### ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢

ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚’çµ„ã¿åˆã‚ã›ã‚‹:

```go
// å°†æ¥ã®æ©Ÿèƒ½ - ã¾ã å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“
results, err := db.HybridQuery(ctx, query, limit, HybridConfig{
	SemanticWeight: 0.7,
	KeywordWeight:  0.3,
})
```

### ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°

ã‚ˆã‚Šå¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã§ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã—ã¦çµæœã‚’æ”¹å–„:

```go
// å°†æ¥ã®æ©Ÿèƒ½ - ã¾ã å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“
reranked := reranker.Rerank(results, query, limit)
```

## ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

1. **ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º**: 500-1000 æ–‡å­—ã‹ã‚‰å§‹ã‚ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«åŸºã¥ã„ã¦èª¿æ•´
2. **é‡è¤‡**: ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã® 10-20% ã‚’é‡è¤‡ã«ä½¿ç”¨
3. **åŸ‹ã‚è¾¼ã¿**: åˆ©ç”¨å¯èƒ½ãªå ´åˆã¯ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®åŸ‹ã‚è¾¼ã¿ã‚’ä½¿ç”¨
4. **ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿**: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨å¼•ç”¨ã®ãŸã‚ã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚ã‚‹
5. **ã‚¨ãƒ©ãƒ¼å‡¦ç†**: æ¤œç´¢å¤±æ•—ã‚’å¸¸ã«é©åˆ‡ã«å‡¦ç†
6. **ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°**: é »ç¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹åŸ‹ã‚è¾¼ã¿ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚’æ¤œè¨
7. **ç›£è¦–**: æ¤œç´¢å“è³ªã‚’è¿½è·¡ã—ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

**ã‚¨ãƒ©ãƒ¼: "Failed to connect to ChromaDB"**
- ChromaDB ãŒå®Ÿè¡Œä¸­ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª: `docker ps | grep chroma`
- ãƒãƒ¼ãƒˆã‚’ç¢ºèª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8000): `curl http://localhost:8000/api/v1/heartbeat`

**ã‚¨ãƒ©ãƒ¼: "OPENAI_API_KEY environment variable is required"**
- API ã‚­ãƒ¼ã‚’è¨­å®š: `export OPENAI_API_KEY=sk-...`

**æ¤œç´¢å“è³ªãŒä½ã„**
- ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã¨é‡è¤‡ã‚’èª¿æ•´
- ç•°ãªã‚‹åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™
- ã‚ˆã‚Šé–¢é€£æ€§ã®é«˜ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ 
- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨

**é«˜ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼**
- ã‚ˆã‚Šå°ã•ã„åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
- çµæœã®æ•°ã‚’æ¸›ã‚‰ã™ (limit ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)
- åŸ‹ã‚è¾¼ã¿ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚’æ¤œè¨
- ãƒ­ãƒ¼ã‚«ãƒ«åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ (å°†æ¥ã®æ©Ÿèƒ½)

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

- åŸºæœ¬çš„ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½¿ç”¨ã®ãŸã‚ã« [Simple Agent](./simple-agent.md) ã‚’æ¢ç´¢
- è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½¿ã£ãŸ [Team Collaboration](./team-demo.md) ã«ã¤ã„ã¦å­¦ã¶
- è¤‡é›‘ãª RAG ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç”¨ã« [Workflow Engine](./workflow-demo.md) ã‚’è©¦ã™
- [AgentOS API](../api/agentos.md) ã§æœ¬ç•ª RAG ã‚’æ§‹ç¯‰

## è¿½åŠ ãƒªã‚½ãƒ¼ã‚¹

- [OpenAI Embeddings ã‚¬ã‚¤ãƒ‰](https://platform.openai.com/docs/guides/embeddings)
- [ChromaDB ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.trychroma.com/)
- [RAG ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹](https://docs.agno.com/advanced/rag)
- [ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¯”è¼ƒ](https://docs.agno.com/storage/vector-dbs)
