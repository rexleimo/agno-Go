# RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) æ¼”ç¤º

## æ¦‚è¿°

æœ¬ç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Agno-Go æ„å»º RAG ç³»ç»Ÿã€‚RAG å°†ä»çŸ¥è¯†åº“æ£€ç´¢ä¿¡æ¯ä¸ LLM æ–‡æœ¬ç”Ÿæˆç›¸ç»“åˆ,ä»¥æä¾›å‡†ç¡®ã€æœ‰æ ¹æ®çš„ç­”æ¡ˆã€‚è¯¥ç³»ç»Ÿä½¿ç”¨ ChromaDB è¿›è¡Œå‘é‡å­˜å‚¨ã€OpenAI åµŒå…¥å’Œè‡ªå®šä¹‰ RAG toolkit æ¥å®ç°è¯­ä¹‰æœç´¢èƒ½åŠ›ã€‚

## ä½ å°†å­¦åˆ°

- å¦‚ä½•åˆ›å»ºå’Œä½¿ç”¨ OpenAI åµŒå…¥
- å¦‚ä½•å°† ChromaDB è®¾ç½®ä¸ºå‘é‡æ•°æ®åº“
- å¦‚ä½•åˆ†å—æ–‡æ¡£ä»¥å®ç°æœ€ä½³æ£€ç´¢
- å¦‚ä½•ä¸º Agent æ„å»ºè‡ªå®šä¹‰ RAG toolkit
- å¦‚ä½•åˆ›å»ºå…·æœ‰çŸ¥è¯†æ£€ç´¢èƒ½åŠ›çš„ Agent
- RAG å®ç°çš„æœ€ä½³å®è·µ

## å‰ç½®è¦æ±‚

- Go 1.21 æˆ–æ›´é«˜ç‰ˆæœ¬
- OpenAI API key
- æœ¬åœ°è¿è¡Œçš„ ChromaDB (é€šè¿‡ Docker)

## è®¾ç½®

1. è®¾ç½®ä½ çš„ OpenAI API key:
```bash
export OPENAI_API_KEY=sk-your-api-key-here
```

2. ä½¿ç”¨ Docker å¯åŠ¨ ChromaDB:
```bash
docker pull chromadb/chroma
docker run -p 8000:8000 chromadb/chroma
```

3. è¿›å…¥ç¤ºä¾‹ç›®å½•:
```bash
cd cmd/examples/rag_demo
```

## å®Œæ•´ä»£ç 

```go
package main

import (
	"context"
	"fmt"
	"log"
	"os"

	"github.com/rexleimo/agno-go/pkg/agno/agent"
	openaiembed "github.com/rexleimo/agno-go/pkg/agno/embeddings/openai"
	"github.com/rexleimo/agno-go/pkg/agno/knowledge"
	openaimodel "github.com/rexleimo/agno-go/pkg/agno/models/openai"
	"github.com/rexleimo/agno-go/pkg/agno/tools/toolkit"
	"github.com/rexleimo/agno-go/pkg/agno/vectordb"
	"github.com/rexleimo/agno-go/pkg/agno/vectordb/chromadb"
)

// RAGToolkit provides knowledge retrieval tools for the agent
type RAGToolkit struct {
	*toolkit.BaseToolkit
	vectorDB vectordb.VectorDB
}

// NewRAGToolkit creates a new RAG toolkit
func NewRAGToolkit(db vectordb.VectorDB) *RAGToolkit {
	t := &RAGToolkit{
		BaseToolkit: toolkit.NewBaseToolkit("knowledge_retrieval"),
		vectorDB:    db,
	}

	// Register search function
	t.RegisterFunction(&toolkit.Function{
		Name:        "search_knowledge",
		Description: "Search the knowledge base for relevant information. Use this to find answers to user questions.",
		Parameters: map[string]toolkit.Parameter{
			"query": {
				Type:        "string",
				Description: "The search query or question",
				Required:    true,
			},
			"limit": {
				Type:        "integer",
				Description: "Maximum number of results to return (default: 3)",
				Required:    false,
			},
		},
		Handler: t.searchKnowledge,
	})

	return t
}

func (t *RAGToolkit) searchKnowledge(ctx context.Context, args map[string]interface{}) (interface{}, error) {
	query, ok := args["query"].(string)
	if !ok {
		return nil, fmt.Errorf("query must be a string")
	}

	limit := 3
	if l, ok := args["limit"].(float64); ok {
		limit = int(l)
	}

	results, err := t.vectorDB.Query(ctx, query, limit, nil)
	if err != nil {
		return nil, fmt.Errorf("failed to search knowledge base: %w", err)
	}

	// Format results for the agent
	var formattedResults []map[string]interface{}
	for i, result := range results {
		formattedResults = append(formattedResults, map[string]interface{}{
			"rank":     i + 1,
			"content":  result.Content,
			"score":    result.Score,
			"metadata": result.Metadata,
		})
	}

	return formattedResults, nil
}

func main() {
	fmt.Println("ğŸš€ RAG (Retrieval-Augmented Generation) Demo")
	fmt.Println("This example demonstrates:")
	fmt.Println("1. Loading documents from files")
	fmt.Println("2. Chunking text into smaller pieces")
	fmt.Println("3. Generating embeddings with OpenAI")
	fmt.Println("4. Storing in ChromaDB vector database")
	fmt.Println("5. Using RAG with an Agent to answer questions")
	fmt.Println()

	// Check environment variables
	openaiKey := os.Getenv("OPENAI_API_KEY")
	if openaiKey == "" {
		log.Fatal("OPENAI_API_KEY environment variable is required")
	}

	ctx := context.Background()

	// Step 1: Create embedding function
	fmt.Println("ğŸ“Š Step 1: Creating OpenAI embedding function...")
	embedFunc, err := openaiembed.New(openaiembed.Config{
		APIKey: openaiKey,
		Model:  "text-embedding-3-small",
	})
	if err != nil {
		log.Fatalf("Failed to create embedding function: %v", err)
	}
	fmt.Printf("   âœ… Created embedding function (model: %s, dimensions: %d)\n\n",
		embedFunc.GetModel(), embedFunc.GetDimensions())

	// Step 2: Create ChromaDB vector database
	fmt.Println("ğŸ’¾ Step 2: Connecting to ChromaDB...")
	db, err := chromadb.New(chromadb.Config{
		BaseURL:           "http://localhost:8000",
		CollectionName:    "rag_demo",
		EmbeddingFunction: embedFunc,
	})
	if err != nil {
		log.Fatalf("Failed to create ChromaDB: %v", err)
	}
	defer db.Close()

	// Create collection
	err = db.CreateCollection(ctx, "", map[string]interface{}{
		"description": "RAG demo knowledge base",
	})
	if err != nil {
		log.Fatalf("Failed to create collection: %v", err)
	}
	fmt.Println("   âœ… Connected to ChromaDB and created collection")

	// Step 3: Load and process documents
	fmt.Println("ğŸ“š Step 3: Loading and processing documents...")

	// Sample documents about AI and ML
	sampleDocs := []knowledge.Document{
		{
			ID:      "doc1",
			Content: "Artificial Intelligence (AI) is the simulation of human intelligence by machines. AI systems can perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. Modern AI is based on machine learning algorithms that can learn from data.",
			Metadata: map[string]interface{}{
				"topic": "AI Overview",
				"date":  "2025-01-01",
			},
		},
		{
			ID:      "doc2",
			Content: "Machine Learning (ML) is a subset of AI that focuses on creating systems that learn from data. Instead of being explicitly programmed, ML models improve their performance through experience. Common ML algorithms include neural networks, decision trees, and support vector machines.",
			Metadata: map[string]interface{}{
				"topic": "Machine Learning",
				"date":  "2025-01-01",
			},
		},
		{
			ID:      "doc3",
			Content: "Vector databases are specialized databases designed to store and query high-dimensional vector embeddings. They enable semantic search by finding similar vectors using distance metrics like cosine similarity or Euclidean distance. Vector databases are essential for RAG (Retrieval-Augmented Generation) systems.",
			Metadata: map[string]interface{}{
				"topic": "Vector Databases",
				"date":  "2025-01-01",
			},
		},
		{
			ID:      "doc4",
			Content: "Retrieval-Augmented Generation (RAG) combines information retrieval with text generation. It first retrieves relevant documents from a knowledge base, then uses a language model to generate responses based on the retrieved context. RAG improves accuracy and reduces hallucinations in AI systems.",
			Metadata: map[string]interface{}{
				"topic": "RAG",
				"date":  "2025-01-01",
			},
		},
		{
			ID:      "doc5",
			Content: "Large Language Models (LLMs) like GPT-4 are neural networks trained on vast amounts of text data. They can understand and generate human-like text, perform reasoning, answer questions, and even write code. LLMs are the foundation of modern AI assistants and chatbots.",
			Metadata: map[string]interface{}{
				"topic": "Large Language Models",
				"date":  "2025-01-01",
			},
		},
	}

	// Chunk documents (optional, useful for large documents)
	chunker := knowledge.NewCharacterChunker(500, 50)
	var allChunks []knowledge.Chunk
	for _, doc := range sampleDocs {
		chunks, err := chunker.Chunk(doc)
		if err != nil {
			log.Printf("Warning: Failed to chunk document %s: %v", doc.ID, err)
			continue
		}
		allChunks = append(allChunks, chunks...)
	}
	fmt.Printf("   âœ… Loaded %d documents, created %d chunks\n", len(sampleDocs), len(allChunks))

	// Step 4: Generate embeddings and store in vector DB
	fmt.Println("\nğŸ”¢ Step 4: Generating embeddings and storing in ChromaDB...")

	var vdbDocs []vectordb.Document
	for _, chunk := range allChunks {
		vdbDocs = append(vdbDocs, vectordb.Document{
			ID:       chunk.ID,
			Content:  chunk.Content,
			Metadata: chunk.Metadata,
			// Embedding will be generated automatically by ChromaDB
		})
	}

	err = db.Add(ctx, vdbDocs)
	if err != nil {
		log.Fatalf("Failed to add documents to vector DB: %v", err)
	}

	count, _ := db.Count(ctx)
	fmt.Printf("   âœ… Stored %d documents in vector database\n\n", count)

	// Step 5: Test retrieval
	fmt.Println("ğŸ” Step 5: Testing knowledge retrieval...")
	testQuery := "What is machine learning?"
	results, err := db.Query(ctx, testQuery, 2, nil)
	if err != nil {
		log.Fatalf("Failed to query: %v", err)
	}

	fmt.Printf("   Query: \"%s\"\n", testQuery)
	fmt.Printf("   Found %d relevant documents:\n", len(results))
	for i, result := range results {
		fmt.Printf("   %d. [Score: %.4f] %s\n", i+1, result.Score,
			truncate(result.Content, 80))
	}
	fmt.Println()

	// Step 6: Create RAG-powered Agent
	fmt.Println("ğŸ¤– Step 6: Creating RAG-powered Agent...")

	// Create OpenAI model
	model, err := openaimodel.New("gpt-4o-mini", openaimodel.Config{
		APIKey:      openaiKey,
		Temperature: 0.7,
		MaxTokens:   500,
	})
	if err != nil {
		log.Fatalf("Failed to create model: %v", err)
	}

	// Create RAG toolkit
	ragToolkit := NewRAGToolkit(db)

	// Create agent with RAG capabilities
	ag, err := agent.New(agent.Config{
		Name:     "RAG Assistant",
		Model:    model,
		Toolkits: []toolkit.Toolkit{ragToolkit},
		Instructions: `You are a helpful AI assistant with access to a knowledge base.
When users ask questions:
1. Use the search_knowledge tool to find relevant information
2. Base your answer on the retrieved information
3. Cite the sources when possible
4. If you can't find relevant information, say so

Always be helpful, accurate, and concise.`,
		MaxLoops: 5,
	})
	if err != nil {
		log.Fatalf("Failed to create agent: %v", err)
	}
	fmt.Println("   âœ… Agent created with RAG capabilities")

	// Step 7: Interactive Q&A
	fmt.Println("ğŸ’¬ Step 7: Interactive Q&A (RAG in action)")
	fmt.Println("=" + string(make([]byte, 60)) + "=")

	questions := []string{
		"What is artificial intelligence?",
		"Explain the difference between AI and machine learning",
		"What are vector databases used for?",
		"How does RAG improve AI systems?",
	}

	for i, question := range questions {
		fmt.Printf("\n[Question %d] User: %s\n", i+1, question)

		output, err := ag.Run(ctx, question)
		if err != nil {
			log.Printf("Error: %v", err)
			continue
		}

		fmt.Printf("Assistant: %s\n", output.Content)
	}

	fmt.Println("\n" + string(make([]byte, 60)) + "=")
	fmt.Println("\nâœ… RAG Demo completed successfully!")
	fmt.Println("\nKey Takeaways:")
	fmt.Println("â€¢ Documents are chunked and embedded automatically")
	fmt.Println("â€¢ Vector database enables semantic search")
	fmt.Println("â€¢ Agent uses RAG to provide accurate, grounded answers")
	fmt.Println("â€¢ Citations and sources improve trustworthiness")

	// Cleanup
	fmt.Println("\nğŸ§¹ Cleaning up...")
	err = db.DeleteCollection(ctx, "rag_demo")
	if err != nil {
		log.Printf("Warning: Failed to delete collection: %v", err)
	} else {
		fmt.Println("   âœ… Deleted demo collection")
	}
}

func truncate(s string, maxLen int) string {
	if len(s) <= maxLen {
		return s
	}
	return s[:maxLen] + "..."
}
```

## ä»£ç è§£é‡Š

### 1. è‡ªå®šä¹‰ RAG Toolkit

```go
type RAGToolkit struct {
	*toolkit.BaseToolkit
	vectorDB vectordb.VectorDB
}
```

RAG toolkit å°è£…äº†å‘é‡æ•°æ®åº“å¹¶æš´éœ²ä¸€ä¸ª `search_knowledge` å‡½æ•°ä¾› Agent è°ƒç”¨:

- æ¥å—æŸ¥è¯¢å­—ç¬¦ä¸²å’Œå¯é€‰çš„é™åˆ¶æ•°
- ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢å‘é‡æ•°æ®åº“
- è¿”å›å¸¦æœ‰ç›¸å…³æ€§åˆ†æ•°çš„æ ¼å¼åŒ–ç»“æœ

### 2. OpenAI åµŒå…¥

```go
embedFunc, err := openaiembed.New(openaiembed.Config{
	APIKey: openaiKey,
	Model:  "text-embedding-3-small",
})
```

- ä½¿ç”¨ OpenAI çš„ `text-embedding-3-small` æ¨¡å‹ (1536 ç»´)
- å°†æ–‡æœ¬è½¬æ¢ä¸ºå¯†é›†å‘é‡è¡¨ç¤º
- å®ç°è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢

### 3. ChromaDB å‘é‡æ•°æ®åº“

```go
db, err := chromadb.New(chromadb.Config{
	BaseURL:           "http://localhost:8000",
	CollectionName:    "rag_demo",
	EmbeddingFunction: embedFunc,
})
```

- è¿æ¥åˆ°æœ¬åœ° ChromaDB å®ä¾‹
- åˆ›å»ºç”¨äºå­˜å‚¨æ–‡æ¡£åµŒå…¥çš„é›†åˆ
- æ·»åŠ æ–‡æ¡£æ—¶è‡ªåŠ¨ç”ŸæˆåµŒå…¥

### 4. æ–‡æ¡£åˆ†å—

```go
chunker := knowledge.NewCharacterChunker(500, 50)
```

- å°†æ–‡æ¡£åˆ†å‰²ä¸º 500 å­—ç¬¦çš„å—
- å—ä¹‹é—´æœ‰ 50 å­—ç¬¦çš„é‡å 
- ä¿ç•™è·¨å—è¾¹ç•Œçš„ä¸Šä¸‹æ–‡
- æ”¹å–„é•¿æ–‡æ¡£çš„æ£€ç´¢å‡†ç¡®æ€§

### 5. å…·æœ‰ RAG èƒ½åŠ›çš„ Agent

```go
ag, err := agent.New(agent.Config{
	Name:     "RAG Assistant",
	Model:    model,
	Toolkits: []toolkit.Toolkit{ragToolkit},
	Instructions: `You are a helpful AI assistant with access to a knowledge base.
When users ask questions:
1. Use the search_knowledge tool to find relevant information
2. Base your answer on the retrieved information
3. Cite the sources when possible
4. If you can't find relevant information, say so`,
	MaxLoops: 5,
})
```

æŒ‡ä»¤å‘Šè¯‰ Agent:
- ä½•æ—¶ä½¿ç”¨çŸ¥è¯†æ£€ç´¢å·¥å…·
- å¦‚ä½•æ•´åˆæ£€ç´¢åˆ°çš„ä¿¡æ¯
- å¼•ç”¨æ¥æºä»¥æé«˜é€æ˜åº¦
- åœ¨ä¿¡æ¯ä¸å¯ç”¨æ—¶ä¿æŒè¯šå®

## è¿è¡Œç¤ºä¾‹

```bash
# ç¡®ä¿ ChromaDB æ­£åœ¨è¿è¡Œ
docker run -p 8000:8000 chromadb/chroma

# è¿è¡Œæ¼”ç¤º
go run main.go
```

## é¢„æœŸè¾“å‡º

```
ğŸš€ RAG (Retrieval-Augmented Generation) Demo
This example demonstrates:
1. Loading documents from files
2. Chunking text into smaller pieces
3. Generating embeddings with OpenAI
4. Storing in ChromaDB vector database
5. Using RAG with an Agent to answer questions

ğŸ“Š Step 1: Creating OpenAI embedding function...
   âœ… Created embedding function (model: text-embedding-3-small, dimensions: 1536)

ğŸ’¾ Step 2: Connecting to ChromaDB...
   âœ… Connected to ChromaDB and created collection

ğŸ“š Step 3: Loading and processing documents...
   âœ… Loaded 5 documents, created 5 chunks

ğŸ”¢ Step 4: Generating embeddings and storing in ChromaDB...
   âœ… Stored 5 documents in vector database

ğŸ” Step 5: Testing knowledge retrieval...
   Query: "What is machine learning?"
   Found 2 relevant documents:
   1. [Score: 0.8234] Machine Learning (ML) is a subset of AI that focuses on creating syste...
   2. [Score: 0.7156] Artificial Intelligence (AI) is the simulation of human intelligence b...

ğŸ¤– Step 6: Creating RAG-powered Agent...
   âœ… Agent created with RAG capabilities

ğŸ’¬ Step 7: Interactive Q&A (RAG in action)
============================================================

[Question 1] User: What is artificial intelligence?
Assistant: Based on the knowledge base, Artificial Intelligence (AI) is the simulation of human intelligence by machines. AI systems can perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. Modern AI is based on machine learning algorithms that can learn from data.

[Question 2] User: Explain the difference between AI and machine learning
Assistant: AI (Artificial Intelligence) is the broader concept of machines simulating human intelligence to perform various tasks. Machine Learning (ML) is a subset of AI that specifically focuses on creating systems that learn from data rather than being explicitly programmed. So while all ML is AI, not all AI is ML. ML improves performance through experience, using algorithms like neural networks and decision trees.

[Question 3] User: What are vector databases used for?
Assistant: According to the knowledge base, vector databases are specialized databases designed to store and query high-dimensional vector embeddings. They enable semantic search by finding similar vectors using distance metrics like cosine similarity or Euclidean distance. Vector databases are essential for RAG (Retrieval-Augmented Generation) systems.

[Question 4] User: How does RAG improve AI systems?
Assistant: RAG (Retrieval-Augmented Generation) improves AI systems by combining information retrieval with text generation. The process first retrieves relevant documents from a knowledge base, then uses a language model to generate responses based on the retrieved context. This approach improves accuracy and reduces hallucinations in AI systems by grounding responses in actual knowledge.

============================================================

âœ… RAG Demo completed successfully!

Key Takeaways:
â€¢ Documents are chunked and embedded automatically
â€¢ Vector database enables semantic search
â€¢ Agent uses RAG to provide accurate, grounded answers
â€¢ Citations and sources improve trustworthiness

ğŸ§¹ Cleaning up...
   âœ… Deleted demo collection
```

## æ ¸å¿ƒæ¦‚å¿µ

### RAG ç®¡é“

1. **æ‘„å–**: åŠ è½½å’Œåˆ†å—æ–‡æ¡£
2. **åµŒå…¥**: å°†å—è½¬æ¢ä¸ºå‘é‡åµŒå…¥
3. **å­˜å‚¨**: å°†åµŒå…¥å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­
4. **æ£€ç´¢**: ç”¨æˆ·æŸ¥è¯¢è¢«åµŒå…¥å¹¶æ‰¾åˆ°ç›¸ä¼¼æ–‡æ¡£
5. **ç”Ÿæˆ**: LLM åŸºäºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ

### è¯­ä¹‰æœç´¢

ä¸å…³é”®è¯æœç´¢ä¸åŒ,è¯­ä¹‰æœç´¢åŸºäºå«ä¹‰æŸ¥æ‰¾æ–‡æ¡£:

- æŸ¥è¯¢: "What is ML?"
- åŒ¹é…: å…³äº "Machine Learning"ã€"neural networks"ã€"training models" çš„æ–‡æ¡£
- ä¼˜äºç²¾ç¡®å…³é”®è¯åŒ¹é…

### åˆ†å—ç­–ç•¥

æ–‡æ¡£åˆ†å—å‚æ•°å½±å“æ£€ç´¢è´¨é‡:

- **å—å¤§å° (500)**: åœ¨ä¸Šä¸‹æ–‡å’Œç²¾ç¡®æ€§ä¹‹é—´å¹³è¡¡
  - å¤ªå°: ä¸¢å¤±ä¸Šä¸‹æ–‡
  - å¤ªå¤§: æ£€ç´¢ä¸ç›¸å…³å†…å®¹

- **é‡å  (50)**: é˜²æ­¢åˆ†å‰²é‡è¦ä¿¡æ¯
  - ç¡®ä¿è·¨å—çš„è¿ç»­æ€§
  - å¯¹äºè·¨è¶Šè¾¹ç•Œçš„å¥å­è‡³å…³é‡è¦

### è‡ªå®šä¹‰ Toolkit

RAG toolkit æ¼”ç¤ºäº†å¦‚ä½•æ„å»ºè‡ªå®šä¹‰å·¥å…·:

```go
t.RegisterFunction(&toolkit.Function{
	Name:        "search_knowledge",
	Description: "Search the knowledge base...",
	Parameters: map[string]toolkit.Parameter{
		"query": {
			Type:        "string",
			Description: "The search query",
			Required:    true,
		},
	},
	Handler: t.searchKnowledge,
})
```

å…³é”®è¦ç´ :
- æ¸…æ™°çš„åç§°å’Œæè¿°ä¾› LLM ç†è§£
- å®šä¹‰è‰¯å¥½çš„å‚æ•°å’Œç±»å‹
- å®ç°é€»è¾‘çš„å¤„ç†å‡½æ•°

## é«˜çº§ç‰¹æ€§

### å…ƒæ•°æ®è¿‡æ»¤

ä½ å¯ä»¥æŒ‰å…ƒæ•°æ®è¿‡æ»¤ç»“æœ:

```go
results, err := db.Query(ctx, query, limit, map[string]interface{}{
	"topic": "Machine Learning",
	"date": map[string]interface{}{
		"$gte": "2025-01-01",
	},
})
```

### æ··åˆæœç´¢

ç»“åˆè¯­ä¹‰å’Œå…³é”®è¯æœç´¢:

```go
// æœªæ¥åŠŸèƒ½ - å°šæœªå®ç°
results, err := db.HybridQuery(ctx, query, limit, HybridConfig{
	SemanticWeight: 0.7,
	KeywordWeight:  0.3,
})
```

### é‡æ’åº

ä½¿ç”¨æ›´å¼ºå¤§çš„æ¨¡å‹é‡æ’åºä»¥æ”¹å–„ç»“æœ:

```go
// æœªæ¥åŠŸèƒ½ - å°šæœªå®ç°
reranked := reranker.Rerank(results, query, limit)
```

## æœ€ä½³å®è·µ

1. **å—å¤§å°**: ä» 500-1000 å­—ç¬¦å¼€å§‹,æ ¹æ®ä½ çš„å†…å®¹è°ƒæ•´
2. **é‡å **: ä½¿ç”¨å—å¤§å°çš„ 10-20% ä½œä¸ºé‡å 
3. **åµŒå…¥**: å¯ç”¨æ—¶ä½¿ç”¨é¢†åŸŸç‰¹å®šçš„åµŒå…¥
4. **å…ƒæ•°æ®**: åŒ…å«å…ƒæ•°æ®ç”¨äºè¿‡æ»¤å’Œå¼•ç”¨
5. **é”™è¯¯å¤„ç†**: æ€»æ˜¯ä¼˜é›…åœ°å¤„ç†æ£€ç´¢å¤±è´¥
6. **ç¼“å­˜**: è€ƒè™‘ç¼“å­˜é¢‘ç¹è®¿é—®çš„åµŒå…¥
7. **ç›‘æ§**: è·Ÿè¸ªæ£€ç´¢è´¨é‡å¹¶è°ƒæ•´å‚æ•°

## æ•…éšœæ’é™¤

**é”™è¯¯: "Failed to connect to ChromaDB"**
- ç¡®ä¿ ChromaDB æ­£åœ¨è¿è¡Œ: `docker ps | grep chroma`
- æ£€æŸ¥ç«¯å£ (é»˜è®¤: 8000): `curl http://localhost:8000/api/v1/heartbeat`

**é”™è¯¯: "OPENAI_API_KEY environment variable is required"**
- è®¾ç½®ä½ çš„ API key: `export OPENAI_API_KEY=sk-...`

**æ£€ç´¢è´¨é‡ä½**
- è°ƒæ•´å—å¤§å°å’Œé‡å 
- å°è¯•ä¸åŒçš„åµŒå…¥æ¨¡å‹
- æ·»åŠ æ›´å¤šç›¸å…³æ–‡æ¡£
- ä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤

**é«˜å»¶è¿Ÿ**
- ä½¿ç”¨æ›´å°çš„åµŒå…¥æ¨¡å‹
- å‡å°‘ç»“æœæ•°é‡ (limit å‚æ•°)
- è€ƒè™‘ç¼“å­˜åµŒå…¥
- ä½¿ç”¨æœ¬åœ°åµŒå…¥æ¨¡å‹ (æœªæ¥åŠŸèƒ½)

## ä¸‹ä¸€æ­¥

- æ¢ç´¢ [Simple Agent](./simple-agent.md) äº†è§£åŸºæœ¬ Agent ç”¨æ³•
- äº†è§£ [Team åä½œ](./team-demo.md) ä½¿ç”¨å¤šä¸ª Agent
- å°è¯• [Workflow å¼•æ“](./workflow-demo.md) æ„å»ºå¤æ‚çš„ RAG ç®¡é“
- ä½¿ç”¨ [AgentOS API](../api/agentos.md) æ„å»ºç”Ÿäº§ RAG

## å…¶ä»–èµ„æº

- [OpenAI Embeddings æŒ‡å—](https://platform.openai.com/docs/guides/embeddings)
- [ChromaDB æ–‡æ¡£](https://docs.trychroma.com/)
- [RAG æœ€ä½³å®è·µ](https://docs.agno.com/advanced/rag)
- [å‘é‡æ•°æ®åº“æ¯”è¾ƒ](https://docs.agno.com/storage/vector-dbs)
