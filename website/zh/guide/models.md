# Models - LLM æä¾›å•†

Agno-Go é€šè¿‡ç»Ÿä¸€æ¥å£æ”¯æŒå¤šä¸ª LLM æä¾›å•†ã€‚

---

## æ”¯æŒçš„æ¨¡å‹

### OpenAI
- GPT-4oã€GPT-4o-miniã€GPT-4 Turboã€GPT-3.5 Turbo
- å®Œæ•´æµå¼ä¼ è¾“æ”¯æŒ
- å‡½æ•°è°ƒç”¨

### Anthropic Claude
- Claude 3.5 Sonnetã€Claude 3 Opusã€Claude 3 Sonnetã€Claude 3 Haiku
- æµå¼ä¼ è¾“æ”¯æŒ
- å·¥å…·ä½¿ç”¨

### Ollama
- æœ¬åœ°è¿è¡Œæ¨¡å‹ (Llamaã€Mistral ç­‰)
- éšç§ä¼˜å…ˆ
- æ—  API è´¹ç”¨

---

## OpenAI

### è®¾ç½®

```go
import "github.com/rexleimo/agno-go/pkg/agno/models/openai"

model, err := openai.New("gpt-4o-mini", openai.Config{
    APIKey:      os.Getenv("OPENAI_API_KEY"),
    Temperature: 0.7,
    MaxTokens:   1000,
})
```

### é…ç½®

```go
type Config struct {
    APIKey      string  // å¿…éœ€: æ‚¨çš„ OpenAI API å¯†é’¥
    BaseURL     string  // å¯é€‰: è‡ªå®šä¹‰ç«¯ç‚¹ (é»˜è®¤: https://api.openai.com/v1)
    Temperature float64 // å¯é€‰: 0.0-2.0 (é»˜è®¤: 0.7)
    MaxTokens   int     // å¯é€‰: æœ€å¤§å“åº” Token æ•°
}
```

### æ”¯æŒçš„æ¨¡å‹

| æ¨¡å‹ | ä¸Šä¸‹æ–‡ | æœ€é€‚åˆ |
|-------|---------|----------|
| `gpt-4o` | 128K | æœ€å¼ºå¤§,å¤šæ¨¡æ€ |
| `gpt-4o-mini` | 128K | å¿«é€Ÿ,ç»æµå®æƒ  |
| `gpt-4-turbo` | 128K | é«˜çº§æ¨ç† |
| `gpt-3.5-turbo` | 16K | ç®€å•ä»»åŠ¡,å¿«é€Ÿ |

### ç¤ºä¾‹

```go
package main

import (
    "context"
    "fmt"
    "log"
    "os"

    "github.com/rexleimo/agno-go/pkg/agno/agent"
    "github.com/rexleimo/agno-go/pkg/agno/models/openai"
)

func main() {
    model, err := openai.New("gpt-4o-mini", openai.Config{
        APIKey:      os.Getenv("OPENAI_API_KEY"),
        Temperature: 0.7,
    })
    if err != nil {
        log.Fatal(err)
    }

    agent, _ := agent.New(agent.Config{
        Name:  "Assistant",
        Model: model,
    })

    output, _ := agent.Run(context.Background(), "Hello!")
    fmt.Println(output.Content)
}
```

---

## Anthropic Claude

### è®¾ç½®

```go
import "github.com/rexleimo/agno-go/pkg/agno/models/anthropic"

model, err := anthropic.New("claude-3-5-sonnet-20241022", anthropic.Config{
    APIKey:    os.Getenv("ANTHROPIC_API_KEY"),
    MaxTokens: 2048,
})
```

### é…ç½®

```go
type Config struct {
    APIKey      string  // å¿…éœ€: æ‚¨çš„ Anthropic API å¯†é’¥
    Temperature float64 // å¯é€‰: 0.0-1.0
    MaxTokens   int     // å¯é€‰: æœ€å¤§å“åº” Token æ•° (é»˜è®¤: 4096)
}
```

### æ”¯æŒçš„æ¨¡å‹

| æ¨¡å‹ | ä¸Šä¸‹æ–‡ | æœ€é€‚åˆ |
|-------|---------|----------|
| `claude-3-5-sonnet-20241022` | 200K | æœ€æ™ºèƒ½,ç¼–ç¨‹ |
| `claude-3-opus-20240229` | 200K | å¤æ‚ä»»åŠ¡ |
| `claude-3-sonnet-20240229` | 200K | å¹³è¡¡æ€§èƒ½ |
| `claude-3-haiku-20240307` | 200K | å¿«é€Ÿå“åº” |

### ç¤ºä¾‹

```go
package main

import (
    "context"
    "fmt"
    "log"
    "os"

    "github.com/rexleimo/agno-go/pkg/agno/agent"
    "github.com/rexleimo/agno-go/pkg/agno/models/anthropic"
)

func main() {
    model, err := anthropic.New("claude-3-5-sonnet-20241022", anthropic.Config{
        APIKey:    os.Getenv("ANTHROPIC_API_KEY"),
        MaxTokens: 2048,
    })
    if err != nil {
        log.Fatal(err)
    }

    agent, _ := agent.New(agent.Config{
        Name:         "Claude",
        Model:        model,
        Instructions: "You are a helpful assistant.",
    })

    output, _ := agent.Run(context.Background(), "Explain quantum computing")
    fmt.Println(output.Content)
}
```

---

## Ollama (æœ¬åœ°æ¨¡å‹)

### è®¾ç½®

1. å®‰è£… Ollama: https://ollama.ai
2. æ‹‰å–æ¨¡å‹: `ollama pull llama2`
3. åœ¨ Agno-Go ä¸­ä½¿ç”¨:

```go
import "github.com/rexleimo/agno-go/pkg/agno/models/ollama"

model, err := ollama.New("llama2", ollama.Config{
    BaseURL: "http://localhost:11434",  // Ollama server
})
```

### é…ç½®

```go
type Config struct {
    BaseURL     string  // å¯é€‰: Ollama æœåŠ¡å™¨ URL (é»˜è®¤: http://localhost:11434)
    Temperature float64 // å¯é€‰: 0.0-1.0
}
```

### æ”¯æŒçš„æ¨¡å‹

Ollama ä¸­å¯ç”¨çš„ä»»ä½•æ¨¡å‹:
- `llama2`, `llama3`, `llama3.1`
- `mistral`, `mixtral`
- `codellama`, `deepseek-coder`
- `qwen2`, `gemma2`

### ç¤ºä¾‹

```go
package main

import (
    "context"
    "fmt"
    "log"

    "github.com/rexleimo/agno-go/pkg/agno/agent"
    "github.com/rexleimo/agno-go/pkg/agno/models/ollama"
)

func main() {
    // Make sure Ollama is running and model is pulled
    model, err := ollama.New("llama2", ollama.Config{
        BaseURL: "http://localhost:11434",
    })
    if err != nil {
        log.Fatal(err)
    }

    agent, _ := agent.New(agent.Config{
        Name:  "Local Assistant",
        Model: model,
    })

    output, _ := agent.Run(context.Background(), "What is Go?")
    fmt.Println(output.Content)
}
```

---

## æ¨¡å‹æ¯”è¾ƒ

### æ€§èƒ½

| æä¾›å•† | é€Ÿåº¦ | æˆæœ¬ | éšç§ | ä¸Šä¸‹æ–‡ |
|----------|-------|------|---------|---------|
| OpenAI GPT-4o-mini | âš¡âš¡âš¡ | ğŸ’° | â˜ï¸ äº‘ç«¯ | 128K |
| OpenAI GPT-4o | âš¡âš¡ | ğŸ’°ğŸ’°ğŸ’° | â˜ï¸ äº‘ç«¯ | 128K |
| Anthropic Claude | âš¡âš¡ | ğŸ’°ğŸ’° | â˜ï¸ äº‘ç«¯ | 200K |
| Ollama | âš¡ | ğŸ†“ å…è´¹ | ğŸ  æœ¬åœ° | å¯å˜ |

### ä½•æ—¶ä½¿ç”¨æ¯ç§

**OpenAI GPT-4o-mini**
- å¼€å‘å’Œæµ‹è¯•
- é«˜å®¹é‡åº”ç”¨
- æˆæœ¬æ•æ„Ÿçš„ä½¿ç”¨åœºæ™¯

**OpenAI GPT-4o**
- å¤æ‚æ¨ç†ä»»åŠ¡
- å¤šæ¨¡æ€åº”ç”¨
- ç”Ÿäº§ç³»ç»Ÿ

**Anthropic Claude**
- é•¿ä¸Šä¸‹æ–‡éœ€æ±‚ (200K Token)
- ç¼–ç¨‹è¾…åŠ©
- å¤æ‚åˆ†æ

**Ollama**
- éšç§è¦æ±‚
- æ— äº’è”ç½‘è¿æ¥
- é›¶ API æˆæœ¬
- å¼€å‘/æµ‹è¯•

---

## åˆ‡æ¢æ¨¡å‹

åœ¨æ¨¡å‹é—´åˆ‡æ¢å¾ˆç®€å•:

```go
// OpenAI
openaiModel, _ := openai.New("gpt-4o-mini", openai.Config{
    APIKey: os.Getenv("OPENAI_API_KEY"),
})

// Claude
claudeModel, _ := anthropic.New("claude-3-5-sonnet-20241022", anthropic.Config{
    APIKey: os.Getenv("ANTHROPIC_API_KEY"),
})

// Ollama
ollamaModel, _ := ollama.New("llama2", ollama.Config{})

// Use the same agent code
agent, _ := agent.New(agent.Config{
    Model: openaiModel,  // or claudeModel, or ollamaModel
})
```

---

## é«˜çº§é…ç½®

### Temperature

æ§åˆ¶éšæœºæ€§ (0.0 = ç¡®å®šæ€§, 1.0+ = åˆ›é€ æ€§):

```go
model, _ := openai.New("gpt-4o-mini", openai.Config{
    Temperature: 0.0,  // Consistent responses
})

model, _ := openai.New("gpt-4o-mini", openai.Config{
    Temperature: 1.5,  // Creative responses
})
```

### Max Tokens

é™åˆ¶å“åº”é•¿åº¦:

```go
model, _ := openai.New("gpt-4o-mini", openai.Config{
    MaxTokens: 500,  // Short responses
})
```

### è‡ªå®šä¹‰ç«¯ç‚¹

ä½¿ç”¨å…¼å®¹çš„ API:

```go
model, _ := openai.New("gpt-4o-mini", openai.Config{
    BaseURL: "https://your-proxy.com/v1",  // Custom endpoint
    APIKey:  "your-key",
})
```

---

## æœ€ä½³å®è·µ

### 1. ç¯å¢ƒå˜é‡

å®‰å…¨åœ°å­˜å‚¨ API å¯†é’¥:

```go
// Good âœ…
APIKey: os.Getenv("OPENAI_API_KEY")

// Bad âŒ
APIKey: "sk-proj-..." // Hardcoded
```

### 2. é”™è¯¯å¤„ç†

å§‹ç»ˆæ£€æŸ¥é”™è¯¯:

```go
model, err := openai.New("gpt-4o-mini", openai.Config{
    APIKey: os.Getenv("OPENAI_API_KEY"),
})
if err != nil {
    log.Fatalf("Failed to create model: %v", err)
}
```

### 3. æ¨¡å‹é€‰æ‹©

æ ¹æ®éœ€æ±‚é€‰æ‹©:

```go
// Development: Fast and cheap
devModel, _ := openai.New("gpt-4o-mini", config)

// Production: More capable
prodModel, _ := openai.New("gpt-4o", config)
```

### 4. Context ç®¡ç†

æ³¨æ„ä¸Šä¸‹æ–‡é™åˆ¶:

```go
// For long conversations, clear memory periodically
if messageCount > 50 {
    agent.ClearMemory()
}
```

---

## ç¯å¢ƒè®¾ç½®

åˆ›å»º `.env` æ–‡ä»¶:

```bash
# OpenAI
OPENAI_API_KEY=sk-proj-...

# Anthropic
ANTHROPIC_API_KEY=sk-ant-...

# Ollama (optional, defaults to localhost)
OLLAMA_BASE_URL=http://localhost:11434
```

åœ¨ä»£ç ä¸­åŠ è½½:

```go
import "github.com/joho/godotenv"

func init() {
    godotenv.Load()
}
```

---

## ä¸‹ä¸€æ­¥

- æ·»åŠ  [Tools](/guide/tools) å¢å¼ºæ¨¡å‹èƒ½åŠ›
- äº†è§£ [Memory](/guide/memory) çš„å¯¹è¯å†å²
- ä½¿ç”¨æ··åˆæ¨¡å‹æ„å»º [Teams](/guide/team)
- æ¢ç´¢ [Examples](/examples/) çš„å®é™…ç”¨æ³•

---

## ç›¸å…³ç¤ºä¾‹

- [Simple Agent](/examples/simple-agent) - OpenAI ç¤ºä¾‹
- [Claude Agent](/examples/claude-agent) - Anthropic ç¤ºä¾‹
- [Ollama Agent](/examples/ollama-agent) - æœ¬åœ°æ¨¡å‹ç¤ºä¾‹
